{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Super-Piano-2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bHWiJvW4vmGM",
        "Jv25m6-Xuzlu",
        "Dj4PwQitvSVa"
      ],
      "authorship_tag": "ABX9TyMnb10PDrIJ4Tt3BhfDyY+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/SuperPiano/blob/master/Super_Piano_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avfslsXnDS4j",
        "colab_type": "text"
      },
      "source": [
        "##Super Piano 2\n",
        "\n",
        "Based on Yuankui Lee's repo and code https://github.com/djosix/Performance-RNN-PyTorch\n",
        "\n",
        "MAKE YOUR OWN SOTA PIANO MUSIC AI MODEL IN UNDER 4 HOURS !!! :)\n",
        "\n",
        "MAESTRO Dataset is courtesy of Google Magenta Team and it is distributed under Attribution-NonCommercial-ShareAlike 4.0 International license.\n",
        "\n",
        "So keep this in mind and respect everyone's copyright, please :)\n",
        "\n",
        "Huge thanks go out to all people who shared these amazing code contributions and made this Colab notebook possible :) Thank you so much, guys!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHWiJvW4vmGM",
        "colab_type": "text"
      },
      "source": [
        "### Setup the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Zz7WiBy9qC",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Install all dependencies and requrements\n",
        "print(3..2..1..lets do it)\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install numpy\n",
        "!pip install tensorboardX\n",
        "!pip install tensorboard\n",
        "!pip install progress\n",
        "!pip install pretty-midi\n",
        "!pip install pypianoroll\n",
        "!pip install matplotlib\n",
        "!pip install mir_eval\n",
        "!pip install librosa\n",
        "!git clone https://github.com/asigalov61/Performance-RNN-PyTorch\n",
        "!nvidia-smi\n",
        "print('Success :) Everything is installed and should work fine :) Enjoy!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv25m6-Xuzlu",
        "colab_type": "text"
      },
      "source": [
        "### Download and Unzip training MIDIs DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBb4QJMl0wyy",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Best Choice/Works best stand-alone) Alex Piano Only Drafts Original 1500 MIDIs \n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'\n",
        "!unzip -j 'AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWphnIOT9sb_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Optional) Google Magenta MAESTRO Piano MIDI Dataset (~1300 MIDIs)\n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip -j maestro-v2.0.0-midi.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj4PwQitvSVa",
        "colab_type": "text"
      },
      "source": [
        "### Prepare and pre-process your MIDI DataSet for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1q2Xa900PuZ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title This may take a while, especially on the large DataSets, so please be patient\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 preprocess.py '/content/Performance-RNN-PyTorch/dataset/midi' '/content/Performance-RNN-PyTorch/dataset/processed' 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhnT38z_yuxp",
        "colab_type": "text"
      },
      "source": [
        "### (Optional) Activate Tensorboard to monitor the progress of the model during training. You can also activate this cell at any other time to view logs/records of all training runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGLZ_Gh4v63C",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Tensorboard Graphs and Stats\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "%tensorboard --logdir /content/Performance-RNN-PyTorch/runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLQcmGNdzfZi",
        "colab_type": "text"
      },
      "source": [
        "###Train your model quickly here :) \n",
        "\n",
        "WARNING: Created/resulting Model may produce (partially) plagiarized (overfitted) output. Excercise care and respect the copyright, please :) NOTE: You can manipulate provided variables below to further influence/improve generated output. Only the first batch is downloaded and plotted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1l-9hW92vJX",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Main Training Loop\n",
        "save_model_every = 200 #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "number_of_batches = 256 #@param {type:\"slider\", min:0, max:512, step:1}\n",
        "window_size = 512 #@param {type:\"slider\", min:0, max:512, step:1}\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 train.py -s save/myModel.sess -d '/content/Performance-RNN-PyTorch/dataset/processed' -i 200 -b 256 -w 512 -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WSwGrMs2qNe",
        "colab_type": "text"
      },
      "source": [
        "###Generate, Plot, Graph, Save, Download, and Render the resulting output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnA3aoTE8SjZ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Main Generation Loop\n",
        "number_of_tokens_to_generate =  1024#@param {type:\"integer\"}\n",
        "model_temperature = 0.7 #@param {type:\"slider\", min:0, max:3, step:0.1}\n",
        "number_of_batches_and_files_to_generate = 1 #@param {type:\"slider\", min:0, max:16, step:1}\n",
        "\n",
        "\n",
        "!python3 generate.py -l 1024 -T 0.7 -b 4 -s '/content/Performance-RNN-PyTorch/save/myModel.sess'\n",
        "print('Successfully exported the output to output-000.mid')\n",
        "print('Downloading output-000.mid')\n",
        "from google.colab import files\n",
        "files.download('/content/Performance-RNN-PyTorch/output/output-000.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxhLgcUzBWt",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot/Graph the Output and Render it for listening (SineWaves)\n",
        "graphs_length_inches = 18 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 4 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "rendered_wav_graph_height = 3 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('SVG')\n",
        "# For plotting\n",
        "import mir_eval.display\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "midi_data = pretty_midi.PrettyMIDI('/content/Performance-RNN-PyTorch/output/output-000.mid')\n",
        "\n",
        "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "\n",
        "\n",
        "roll = np.zeros([int(graphs_length_inches), 128])\n",
        "# Plot the output\n",
        "\n",
        "track = Multitrack('/content/Performance-RNN-PyTorch/output/output-000.mid', name='track')\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "ax2 = plot_piano_roll(midi_data, 24, 84)\n",
        "plt.show(block=False)\n",
        "\n",
        "# Generate rendering (WAV)\n",
        "\n",
        "\n",
        "audio = midi_data.synthesize()\n",
        "\n",
        "print(audio.shape)\n",
        "\n",
        "plt.figure(figsize=[graphs_length_inches, rendered_wav_graph_height])\n",
        "plt.plot(audio)\n",
        "plt.show(block=False)\n",
        "\n",
        "import IPython.display as ipd\n",
        "ipd.Audio(audio, rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}