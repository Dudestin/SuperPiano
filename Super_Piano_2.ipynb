{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Super-Piano-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1blMgPtY7OQr2h4HaZCtmYzzbrVFhNaGo",
      "authorship_tag": "ABX9TyP059YISUvwJx+ltDx6ZpSL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/SuperPiano/blob/master/Super_Piano_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avfslsXnDS4j",
        "colab_type": "text"
      },
      "source": [
        "#Super Piano 2\n",
        "\n",
        "MAKE YOUR OWN SOTA PIANO MUSIC AI MODEL IN UNDER 4 HOURS !!! :)\n",
        "\n",
        "Based on Yuankui Lee's repo and code https://github.com/djosix/Performance-RNN-PyTorch\n",
        "\n",
        "MAESTRO Dataset is courtesy of Google Magenta Team and it is distributed under Attribution-NonCommercial-ShareAlike 4.0 International license.\n",
        "\n",
        "So keep this in mind and respect everyone's copyright, please :)\n",
        "\n",
        "Huge thanks go out to all people who shared these amazing code contributions and made this Colab notebook possible :) Thank you so much, guys!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHWiJvW4vmGM",
        "colab_type": "text"
      },
      "source": [
        "## Setup the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Zz7WiBy9qC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install all dependencies and requrements\n",
        "print('3..2..1..lets do it')\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install numpy\n",
        "%tensorflow_version 1.x\n",
        "!pip install tensorflow-gpu==1.15\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n",
        "import tensorflow as tf\n",
        "!v1.disable_v2_behavior()\n",
        "!pip install tensorboardX\n",
        "!pip install tensorboard\n",
        "!pip install progress\n",
        "!pip install pretty-midi\n",
        "!pip install pypianoroll\n",
        "!pip install matplotlib\n",
        "!pip install mir_eval\n",
        "!pip install librosa\n",
        "!pip install pyFluidSynth\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!git clone https://github.com/asigalov61/Performance-RNN-PyTorch\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 /content/font.sf2\n",
        "from midi2audio import FluidSynth\n",
        "from google.colab import output\n",
        "from IPython.display import display, Javascript, HTML, Audio\n",
        "!nvidia-smi\n",
        "print('Success :) Everything is installed and should work fine :) Enjoy!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv25m6-Xuzlu",
        "colab_type": "text"
      },
      "source": [
        "### Download and Unzip training MIDIs DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pAIO_n9wKKG",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title (The Best Choice/Works best stand-alone) Super Piano 2 Original 2500 MIDIs of Piano Music\n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://github.com/asigalov61/SuperPiano/raw/master/Super_Piano_2_MIDI_DataSet_CC_BY_NC_SA.zip'\n",
        "!unzip -j 'Super_Piano_2_MIDI_DataSet_CC_BY_NC_SA.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBb4QJMl0wyy",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Second Best Choice/Works best stand-alone) Alex Piano Only Drafts Original 1500 MIDIs \n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'\n",
        "!unzip -j 'AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWphnIOT9sb_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Optional) Google Magenta MAESTRO Piano MIDI Dataset (~1300 MIDIs)\n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip -j maestro-v2.0.0-midi.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLOHEIgemfRD",
        "colab_type": "text"
      },
      "source": [
        "###(Optional) Download the pre-trained model to generate music without training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMC1hNL6mukM",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Super Piano 2 Pre-Trained Model (floss=1.11 - 12.5k training steps)\n",
        "%cd /content/Performance-RNN-PyTorch/save\n",
        "!wget 'https://superpiano.s3-us-west-1.amazonaws.com/Super-Piano-2-floss1-118232-steps-12639-time-2-20hrs.sess'\n",
        "!mv 'Super-Piano-2-floss1-118232-steps-12639-time-2-20hrs.sess' '/content/Perfomance-RNN-PyTorch/save/myModel.sess'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj4PwQitvSVa",
        "colab_type": "text"
      },
      "source": [
        "### Prepare and pre-process your MIDI DataSet for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1q2Xa900PuZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title This may take a while, especially on the large DataSets, so please be patient\n",
        "number_of_parallel_threads = 64 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 preprocess.py '/content/Performance-RNN-PyTorch/dataset/midi' '/content/Performance-RNN-PyTorch/dataset/processed' $number_of_parallel_threads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhnT38z_yuxp",
        "colab_type": "text"
      },
      "source": [
        "### (Optional) Activate Tensorboard to monitor the progress of the model during training. You can also activate this cell at any other time to view logs/records of all training runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGLZ_Gh4v63C",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Tensorboard Graphs and Stats\n",
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "%tensorboard --logdir /content/Performance-RNN-PyTorch/runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLQcmGNdzfZi",
        "colab_type": "text"
      },
      "source": [
        "###Train your model quickly here :) \n",
        "\n",
        "WARNING: Created/resulting Model may produce (partially) plagiarized (overfitted) output. Excercise care and respect the copyright, please :) NOTE: You can manipulate provided variables below to further influence/improve generated output. Only the first batch is downloaded and plotted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1l-9hW92vJX",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "a01fe98d-d25d-4f03-e8ee-0431ce46c2d8"
      },
      "source": [
        "#@title Main Training Loop\n",
        "save_model_every = 200 #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "number_of_batches = 256 #@param {type:\"slider\", min:0, max:512, step:1}\n",
        "window_size = 256 #@param {type:\"slider\", min:0, max:512, step:1}\n",
        "control_ratio = 0.3 #@param {type:\"number\"}\n",
        "teacher_forcing_ratio = 0.7 #@param {type:\"number\"}\n",
        "stride_size = 0\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 train.py -s save/myModel.sess -d '/content/Performance-RNN-PyTorch/dataset/processed' -i $save_model_every -b $number_of_batches -w $window_size -c $control_ratio -T $teacher_forcing_ratio -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 1120, loss: 2.2316296100616455\n",
            "iter 1121, loss: 2.446110486984253\n",
            "iter 1122, loss: 2.0349104404449463\n",
            "iter 1123, loss: 2.246392250061035\n",
            "iter 1124, loss: 2.018651247024536\n",
            "iter 1125, loss: 2.0149898529052734\n",
            "iter 1126, loss: 2.264951705932617\n",
            "iter 1127, loss: 2.204739809036255\n",
            "iter 1128, loss: 2.2466301918029785\n",
            "iter 1129, loss: 2.429953098297119\n",
            "iter 1130, loss: 2.015986204147339\n",
            "iter 1131, loss: 2.173287868499756\n",
            "iter 1132, loss: 2.0165324211120605\n",
            "iter 1133, loss: 2.338613271713257\n",
            "iter 1134, loss: 2.4764175415039062\n",
            "iter 1135, loss: 2.2759077548980713\n",
            "iter 1136, loss: 2.2067384719848633\n",
            "iter 1137, loss: 2.1159756183624268\n",
            "iter 1138, loss: 2.1711912155151367\n",
            "iter 1139, loss: 2.24228835105896\n",
            "iter 1140, loss: 2.29235577583313\n",
            "iter 1141, loss: 2.3174221515655518\n",
            "iter 1142, loss: 2.119373083114624\n",
            "iter 1143, loss: 2.0273196697235107\n",
            "iter 1144, loss: 2.249260663986206\n",
            "iter 1145, loss: 2.339054584503174\n",
            "iter 1146, loss: 2.3897132873535156\n",
            "iter 1147, loss: 2.0867087841033936\n",
            "iter 1148, loss: 2.2581467628479004\n",
            "iter 1149, loss: 1.9717432260513306\n",
            "iter 1150, loss: 2.299747943878174\n",
            "iter 1151, loss: 2.342594623565674\n",
            "iter 1152, loss: 2.263038396835327\n",
            "iter 1153, loss: 1.9652488231658936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WSwGrMs2qNe",
        "colab_type": "text"
      },
      "source": [
        "###Generate, Plot, Graph, Save, Download, and Render the resulting output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nQKPp51If-V",
        "colab_type": "text"
      },
      "source": [
        "NOTES: Control option -c takes commands or a processed .data file path.\n",
        "E.g., \"PITCH_HISTOGRAM;NOTE_DENSITY\" like \"2,0,1,1,0,1,0,1,1,0,0,1;4\", or \";3\" which gives all pitches the same probability or a /path/to/processed/midi/file.data\" to use the specific control sequence from the given processed data file. Option -S stands for Stochastic Beam Search Option"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnA3aoTE8SjZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "number_of_tokens_to_generate = 2048 #@param {type:\"slider\", min:128, max:8192, step:64}\n",
        "model_temperature = 0.8 #@param {type:\"slider\", min:0, max:5, step:0.1}\n",
        "number_of_batches_and_files_to_generate = 1 #@param {type:\"slider\", min:0, max:16, step:1}\n",
        "full_model_path_and_file_name = \"/content/Performance-RNN-PyTorch/save/myModel.sess\" #@param {type:\"string\"}\n",
        "greedy_ratio = \"0.8\" #@param {type:\"string\"}\n",
        "generation_control_seed = \"\" #@param {type:\"string\"}\n",
        "extra_flags = \"\" #@param {type:\"string\"}\n",
        "\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "\n",
        "!python3 generate.py -l $number_of_tokens_to_generate -T $model_temperature -b $number_of_batches_and_files_to_generate -s $full_model_path_and_file_name -g $greedy_ratio $generation_control_seed $extra_flags\n",
        "\n",
        "print('Successfully exported the output to output-000.mid')\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/Performance-RNN-PyTorch/output/output-000.mid')\n",
        "FluidSynth(\"/content/font.sf2\").midi_to_audio('/content/Performance-RNN-PyTorch/output/output-000.mid','output_wav.wav')\n",
        "\n",
        "# set the src and play\n",
        "Audio(\"output_wav.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxhLgcUzBWt",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot and Graph the Output :) Only first batch MIDI file is plotted and displayed \n",
        "graphs_length_inches = 18 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 6 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "rendered_wav_graph_height = 3 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('SVG')\n",
        "# For plotting\n",
        "import mir_eval.display\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "midi_data = pretty_midi.PrettyMIDI('/content/Performance-RNN-PyTorch/output/output-000.mid')\n",
        "\n",
        "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "\n",
        "\n",
        "roll = np.zeros([int(graphs_length_inches), 128])\n",
        "# Plot the output\n",
        "\n",
        "track = Multitrack('/content/Performance-RNN-PyTorch/output/output-000.mid', name='track')\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "ax2 = plot_piano_roll(midi_data, 24, 84)\n",
        "plt.show(block=False)\n",
        "\n",
        "# Generate rendering (WAV)\n",
        "\n",
        "\n",
        "#audio = midi_data.Synthesize()\n",
        "\n",
        "#print(audio.shape)\n",
        "\n",
        "#plt.figure(figsize=[graphs_length_inches, rendered_wav_graph_height])\n",
        "#plt.plot(audio)\n",
        "#plt.show(block=False)\n",
        "\n",
        "#import IPython.display as ipd\n",
        "#ipd.Audio(audio, rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}