{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Super-Piano-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1blMgPtY7OQr2h4HaZCtmYzzbrVFhNaGo",
      "authorship_tag": "ABX9TyNXIkFjK5XmcQCXGFp/9UDt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/SuperPiano/blob/master/Super_Piano_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avfslsXnDS4j",
        "colab_type": "text"
      },
      "source": [
        "##Super Piano 2\n",
        "\n",
        "MAKE YOUR OWN SOTA PIANO MUSIC AI MODEL IN UNDER 4 HOURS !!! :)\n",
        "\n",
        "Based on Yuankui Lee's repo and code https://github.com/djosix/Performance-RNN-PyTorch\n",
        "\n",
        "MAESTRO Dataset is courtesy of Google Magenta Team and it is distributed under Attribution-NonCommercial-ShareAlike 4.0 International license.\n",
        "\n",
        "So keep this in mind and respect everyone's copyright, please :)\n",
        "\n",
        "Huge thanks go out to all people who shared these amazing code contributions and made this Colab notebook possible :) Thank you so much, guys!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHWiJvW4vmGM",
        "colab_type": "text"
      },
      "source": [
        "### Setup the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Zz7WiBy9qC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install all dependencies and requrements\n",
        "print('3..2..1..lets do it')\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install numpy\n",
        "%tensorflow_version 1.x\n",
        "!pip install tensorflow-gpu==1.15\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n",
        "import tensorflow as tf\n",
        "!v1.disable_v2_behavior()\n",
        "!pip install tensorboardX\n",
        "!pip install tensorboard\n",
        "!pip install progress\n",
        "!pip install pretty-midi\n",
        "!pip install pypianoroll\n",
        "!pip install matplotlib\n",
        "!pip install mir_eval\n",
        "!pip install librosa\n",
        "!pip install pyFluidSynth\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!git clone https://github.com/asigalov61/Performance-RNN-PyTorch\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 /content/font.sf2\n",
        "from midi2audio import FluidSynth\n",
        "from google.colab import output\n",
        "from IPython.display import display, Javascript, HTML, Audio\n",
        "!nvidia-smi\n",
        "print('Success :) Everything is installed and should work fine :) Enjoy!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv25m6-Xuzlu",
        "colab_type": "text"
      },
      "source": [
        "### Download and Unzip training MIDIs DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBb4QJMl0wyy",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Best Choice/Works best stand-alone) Alex Piano Only Drafts Original 1500 MIDIs \n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'\n",
        "!unzip -j 'AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWphnIOT9sb_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Optional) Google Magenta MAESTRO Piano MIDI Dataset (~1300 MIDIs)\n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip -j maestro-v2.0.0-midi.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj4PwQitvSVa",
        "colab_type": "text"
      },
      "source": [
        "### Prepare and pre-process your MIDI DataSet for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1q2Xa900PuZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title This may take a while, especially on the large DataSets, so please be patient\n",
        "number_of_parallel_threads = 64 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 preprocess.py '/content/Performance-RNN-PyTorch/dataset/midi' '/content/Performance-RNN-PyTorch/dataset/processed' $number_of_parallel_threads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhnT38z_yuxp",
        "colab_type": "text"
      },
      "source": [
        "### (Optional) Activate Tensorboard to monitor the progress of the model during training. You can also activate this cell at any other time to view logs/records of all training runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGLZ_Gh4v63C",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Tensorboard Graphs and Stats\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "%tensorboard --logdir /content/Performance-RNN-PyTorch/runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLQcmGNdzfZi",
        "colab_type": "text"
      },
      "source": [
        "###Train your model quickly here :) \n",
        "\n",
        "WARNING: Created/resulting Model may produce (partially) plagiarized (overfitted) output. Excercise care and respect the copyright, please :) NOTE: You can manipulate provided variables below to further influence/improve generated output. Only the first batch is downloaded and plotted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1l-9hW92vJX",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "2c95e3e4-7e07-4218-cfdb-c629965e46fa"
      },
      "source": [
        "#@title Main Training Loop\n",
        "save_model_every = 200 #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "number_of_batches = 256 #@param {type:\"slider\", min:0, max:512, step:1}\n",
        "window_size = 256 #@param {type:\"slider\", min:0, max:512, step:1}\n",
        "control_ratio = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "teacher_forcing_ratio = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "stride_size = 10 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 train.py -s save/myModel.sess -d '/content/Performance-RNN-PyTorch/dataset/processed' -i $save_model_every -b $number_of_batches -w $window_size -c $control_ratio -T $teacher_forcing_ratio -S $stride_size -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 3604, loss: 2.3027162551879883\n",
            "iter 3605, loss: 2.297231435775757\n",
            "iter 3606, loss: 2.2733800411224365\n",
            "iter 3607, loss: 2.259855031967163\n",
            "iter 3608, loss: 2.4420058727264404\n",
            "iter 3609, loss: 2.485579490661621\n",
            "iter 3610, loss: 2.5336952209472656\n",
            "iter 3611, loss: 2.629079580307007\n",
            "iter 3612, loss: 2.2364137172698975\n",
            "iter 3613, loss: 2.3233039379119873\n",
            "iter 3614, loss: 2.420461416244507\n",
            "iter 3615, loss: 2.194575548171997\n",
            "iter 3616, loss: 2.577948570251465\n",
            "iter 3617, loss: 2.2760605812072754\n",
            "iter 3618, loss: 2.3872733116149902\n",
            "iter 3619, loss: 2.19643497467041\n",
            "iter 3620, loss: 2.5720386505126953\n",
            "iter 3621, loss: 2.2841694355010986\n",
            "iter 3622, loss: 2.225231647491455\n",
            "iter 3623, loss: 2.481477975845337\n",
            "iter 3624, loss: 2.462383985519409\n",
            "iter 3625, loss: 2.400101900100708\n",
            "iter 3626, loss: 2.4362032413482666\n",
            "iter 3627, loss: 2.5280606746673584\n",
            "iter 3628, loss: 2.2311058044433594\n",
            "iter 3629, loss: 2.4536705017089844\n",
            "iter 3630, loss: 2.604505777359009\n",
            "iter 3631, loss: 2.2385334968566895\n",
            "iter 3632, loss: 2.4746925830841064\n",
            "iter 3633, loss: 2.51379656791687\n",
            "iter 3634, loss: 2.5042884349823\n",
            "iter 3635, loss: 2.3116719722747803\n",
            "iter 3636, loss: 2.435683250427246\n",
            "iter 3637, loss: 2.4066522121429443\n",
            "iter 3638, loss: 2.306123971939087\n",
            "iter 3639, loss: 2.210294485092163\n",
            "iter 3640, loss: 2.3631033897399902\n",
            "iter 3641, loss: 2.193593740463257\n",
            "iter 3642, loss: 2.442234754562378\n",
            "Saving to save/myModel.sess\n",
            "Done saving\n",
            "iter 3643, loss: 2.241969108581543\n",
            "iter 3644, loss: 2.340492010116577\n",
            "iter 3645, loss: 2.2685227394104004\n",
            "iter 3646, loss: 2.3934805393218994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WSwGrMs2qNe",
        "colab_type": "text"
      },
      "source": [
        "###Generate, Plot, Graph, Save, Download, and Render the resulting output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnA3aoTE8SjZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "number_of_tokens_to_generate = 1024 #@param {type:\"slider\", min:128, max:8192, step:64}\n",
        "model_temperature = 0.8 #@param {type:\"slider\", min:0, max:3, step:0.1}\n",
        "number_of_batches_and_files_to_generate = 1 #@param {type:\"slider\", min:0, max:16, step:1}\n",
        "full_model_path_and_file_name = \"/content/Performance-RNN-PyTorch/save/myModel.sess\" #@param {type:\"string\"}\n",
        "extra_flags = \"-S\" #@param {type:\"string\"}\n",
        "generation_control_seed = \"-c '5,0,4,0,4,1,0,5,0,4,0,1;3'\" #@param {type:\"string\"}\n",
        "greedy_ratio = 0.9 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "\n",
        "!python3 generate.py -l $number_of_tokens_to_generate -T $model_temperature -b $number_of_batches_and_files_to_generate -s $full_model_path_and_file_name $extra_flags $greedy_ratio $generation_control_seed\n",
        "\n",
        "print('Successfully exported the output to output-000.mid')\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/Performance-RNN-PyTorch/output/output-000.mid')\n",
        "FluidSynth(\"/content/font.sf2\").midi_to_audio('/content/Performance-RNN-PyTorch/output/output-000.mid','output_wav.wav')\n",
        "\n",
        "# set the src and play\n",
        "Audio(\"output_wav.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na8Qc2CsshaR",
        "colab_type": "text"
      },
      "source": [
        "NOTES: Control takes commands or a processed .data file path.\n",
        "E.g., \"PITCH_HISTOGRAM;NOTE_DENSITY\" like \"2,0,1,1,0,1,0,1,1,0,0,1;4\", or \";3\" which gives all pitches the same probability or a /path/to/processed/midi/file.data\" to use the specific control sequence from the given processed data file. Option -S stands for Stochastic Beam Search (use True or False after the option)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZcn3OeVryGy",
        "colab_type": "text"
      },
      "source": [
        "[-c takes C,C#,D,D#,E,F,F#,G,G#,A,A#,B;note_density] \n",
        "[-S stands for Stochaistic Beam Search] \n",
        "[-g is a Greedy Ratio]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxhLgcUzBWt",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot and Graph the Output :) Only first batch MIDI file is plotted and displayed \n",
        "graphs_length_inches = 18 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 6 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "rendered_wav_graph_height = 3 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('SVG')\n",
        "# For plotting\n",
        "import mir_eval.display\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "midi_data = pretty_midi.PrettyMIDI('/content/Performance-RNN-PyTorch/output/output-000.mid')\n",
        "\n",
        "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "\n",
        "\n",
        "roll = np.zeros([int(graphs_length_inches), 128])\n",
        "# Plot the output\n",
        "\n",
        "track = Multitrack('/content/Performance-RNN-PyTorch/output/output-000.mid', name='track')\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "ax2 = plot_piano_roll(midi_data, 24, 84)\n",
        "plt.show(block=False)\n",
        "\n",
        "# Generate rendering (WAV)\n",
        "\n",
        "\n",
        "#audio = midi_data.Synthesize()\n",
        "\n",
        "#print(audio.shape)\n",
        "\n",
        "#plt.figure(figsize=[graphs_length_inches, rendered_wav_graph_height])\n",
        "#plt.plot(audio)\n",
        "#plt.show(block=False)\n",
        "\n",
        "#import IPython.display as ipd\n",
        "#ipd.Audio(audio, rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}