{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Super-Piano-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1blMgPtY7OQr2h4HaZCtmYzzbrVFhNaGo",
      "authorship_tag": "ABX9TyOhvMuypO2A+9J4v9fip5uA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/SuperPiano/blob/master/Super_Piano_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avfslsXnDS4j",
        "colab_type": "text"
      },
      "source": [
        "##Super Piano 2\n",
        "\n",
        "Based on Yuankui Lee's repo and code https://github.com/djosix/Performance-RNN-PyTorch\n",
        "\n",
        "MAKE YOUR OWN SOTA PIANO MUSIC AI MODEL IN UNDER 4 HOURS !!! :)\n",
        "\n",
        "MAESTRO Dataset is courtesy of Google Magenta Team and it is distributed under Attribution-NonCommercial-ShareAlike 4.0 International license.\n",
        "\n",
        "So keep this in mind and respect everyone's copyright, please :)\n",
        "\n",
        "Huge thanks go out to all people who shared these amazing code contributions and made this Colab notebook possible :) Thank you so much, guys!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHWiJvW4vmGM",
        "colab_type": "text"
      },
      "source": [
        "### Setup the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2Zz7WiBy9qC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install all dependencies and requrements\n",
        "print('3..2..1..lets do it')\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install numpy\n",
        "%tensorflow_version 1.x\n",
        "!pip install tensorflow-gpu==1.15\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n",
        "import tensorflow as tf\n",
        "!v1.disable_v2_behavior()\n",
        "!pip install tensorboardX\n",
        "!pip install tensorboard\n",
        "!pip install progress\n",
        "!pip install pretty-midi\n",
        "!pip install pypianoroll\n",
        "!pip install matplotlib\n",
        "!pip install mir_eval\n",
        "!pip install librosa\n",
        "!pip install pyFluidSynth\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!git clone https://github.com/asigalov61/Performance-RNN-PyTorch\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 /content/font.sf2\n",
        "from midi2audio import FluidSynth\n",
        "from google.colab import output\n",
        "from IPython.display import display, Javascript, HTML, Audio\n",
        "!nvidia-smi\n",
        "print('Success :) Everything is installed and should work fine :) Enjoy!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv25m6-Xuzlu",
        "colab_type": "text"
      },
      "source": [
        "### Download and Unzip training MIDIs DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBb4QJMl0wyy",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Best Choice/Works best stand-alone) Alex Piano Only Drafts Original 1500 MIDIs \n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'\n",
        "!unzip -j 'AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWphnIOT9sb_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Optional) Google Magenta MAESTRO Piano MIDI Dataset (~1300 MIDIs)\n",
        "%cd /content/Performance-RNN-PyTorch/dataset/midi\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip -j maestro-v2.0.0-midi.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj4PwQitvSVa",
        "colab_type": "text"
      },
      "source": [
        "### Prepare and pre-process your MIDI DataSet for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1q2Xa900PuZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title This may take a while, especially on the large DataSets, so please be patient\n",
        "number_of_parallel_threads = 64 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 preprocess.py '/content/Performance-RNN-PyTorch/dataset/midi' '/content/Performance-RNN-PyTorch/dataset/processed' $number_of_parallel_threads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhnT38z_yuxp",
        "colab_type": "text"
      },
      "source": [
        "### (Optional) Activate Tensorboard to monitor the progress of the model during training. You can also activate this cell at any other time to view logs/records of all training runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGLZ_Gh4v63C",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Tensorboard Graphs and Stats\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "%tensorboard --logdir /content/Performance-RNN-PyTorch/runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLQcmGNdzfZi",
        "colab_type": "text"
      },
      "source": [
        "###Train your model quickly here :) \n",
        "\n",
        "WARNING: Created/resulting Model may produce (partially) plagiarized (overfitted) output. Excercise care and respect the copyright, please :) NOTE: You can manipulate provided variables below to further influence/improve generated output. Only the first batch is downloaded and plotted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1l-9hW92vJX",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "e7e14baa-a6b6-42d2-92e7-23c727f1c322"
      },
      "source": [
        "#@title Main Training Loop\n",
        "save_model_every = 200 #@param {type:\"slider\", min:0, max:1000, step:10}\n",
        "number_of_batches = 256 #@param {type:\"slider\", min:0, max:512, step:1}\n",
        "window_size = 256 #@param {type:\"slider\", min:0, max:512, step:1}\n",
        "control_ratio = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "teacher_forcing_ratio = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "stride_size = 10 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 train.py -s save/myModel.sess -d '/content/Performance-RNN-PyTorch/dataset/processed' -i $save_model_every -b $number_of_batches -w $window_size -c $control_ratio -T $teacher_forcing_ratio -S $stride_size -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 1005, loss: 2.7394115924835205\n",
            "iter 1006, loss: 2.859096050262451\n",
            "iter 1007, loss: 2.762364625930786\n",
            "iter 1008, loss: 2.5444869995117188\n",
            "iter 1009, loss: 2.897078514099121\n",
            "iter 1010, loss: 2.710644245147705\n",
            "iter 1011, loss: 2.6470556259155273\n",
            "iter 1012, loss: 2.725670576095581\n",
            "iter 1013, loss: 2.5598742961883545\n",
            "iter 1014, loss: 2.7882168292999268\n",
            "iter 1015, loss: 2.639683485031128\n",
            "iter 1016, loss: 2.737595319747925\n",
            "iter 1017, loss: 2.82126522064209\n",
            "iter 1018, loss: 2.676548957824707\n",
            "iter 1019, loss: 2.6607861518859863\n",
            "iter 1020, loss: 2.5972740650177\n",
            "iter 1021, loss: 2.8911936283111572\n",
            "iter 1022, loss: 2.8424971103668213\n",
            "iter 1023, loss: 2.8227698802948\n",
            "iter 1024, loss: 2.6253206729888916\n",
            "iter 1025, loss: 2.7412052154541016\n",
            "iter 1026, loss: 2.8641340732574463\n",
            "iter 1027, loss: 2.6154773235321045\n",
            "iter 1028, loss: 2.8244271278381348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WSwGrMs2qNe",
        "colab_type": "text"
      },
      "source": [
        "###Generate, Plot, Graph, Save, Download, and Render the resulting output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnA3aoTE8SjZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Main Generation Loop -c takes C,C#,D,D#,E,F,F#,G,G#,A,A#,B;note_density -S is Stochaistic Beam Search -g is a Greedy Ration\n",
        "number_of_tokens_to_generate = 1024 #@param {type:\"slider\", min:128, max:8192, step:64}\n",
        "model_temperature = 0.8 #@param {type:\"slider\", min:0, max:3, step:0.1}\n",
        "number_of_batches_and_files_to_generate = 1 #@param {type:\"slider\", min:0, max:16, step:1}\n",
        "full_model_path_and_file_name = \"/content/Performance-RNN-PyTorch/save/myModel.sess\" #@param {type:\"string\"}\n",
        "extra_flags = \"-S -g 0.8\" #@param {type:\"string\"}\n",
        "%cd /content/Performance-RNN-PyTorch\n",
        "!python3 generate.py -l $number_of_tokens_to_generate -T $model_temperature -b $number_of_batches_and_files_to_generate -s $full_model_path_and_file_name $extra_flags\n",
        "print('Successfully exported the output to output-000.mid')\n",
        "#print('Downloading output-000.mid')\n",
        "from google.colab import files\n",
        "files.download('/content/Performance-RNN-PyTorch/output/output-000.mid')\n",
        "FluidSynth(\"/content/font.sf2\").midi_to_audio('/content/Performance-RNN-PyTorch/output/output-000.mid','output_wav.wav')\n",
        "# set the src and play\n",
        "Audio(\"output_wav.wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxhLgcUzBWt",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot and Graph the Output :) Only first batch MIDI file is plotted and displayed \n",
        "graphs_length_inches = 18 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 6 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "rendered_wav_graph_height = 3 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('SVG')\n",
        "# For plotting\n",
        "import mir_eval.display\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "midi_data = pretty_midi.PrettyMIDI('/content/Performance-RNN-PyTorch/output/output-000.mid')\n",
        "\n",
        "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "\n",
        "\n",
        "roll = np.zeros([int(graphs_length_inches), 128])\n",
        "# Plot the output\n",
        "\n",
        "track = Multitrack('/content/Performance-RNN-PyTorch/output/output-000.mid', name='track')\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "ax2 = plot_piano_roll(midi_data, 24, 84)\n",
        "plt.show(block=False)\n",
        "\n",
        "# Generate rendering (WAV)\n",
        "\n",
        "\n",
        "#audio = midi_data.Synthesize()\n",
        "\n",
        "#print(audio.shape)\n",
        "\n",
        "#plt.figure(figsize=[graphs_length_inches, rendered_wav_graph_height])\n",
        "#plt.plot(audio)\n",
        "#plt.show(block=False)\n",
        "\n",
        "#import IPython.display as ipd\n",
        "#ipd.Audio(audio, rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}