{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "SuperPiano5 (Reformer_TPU).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/SuperPiano/blob/master/SuperPiano5_(Reformer_TPU).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgn4KUAATtXS"
      },
      "source": [
        "# Super Piano 5 (v.0.5)\r\n",
        "\r\n",
        "Uses line-by-line dataset from Intelligent VIRTUOSO/TMIDI-TXT Processor\r\n",
        "\r\n",
        "https://github.com/asigalov61/Intelligent-VIRTUOSO\r\n",
        "\r\n",
        "Most of the colab as found here:\r\n",
        "\r\n",
        "https://github.com/jlilleberg/Philosophical-Text-Generation-using-Reformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QINqPZH6FzB3"
      },
      "source": [
        "# Install dependencies\n",
        "!pip install --upgrade -q jax\n",
        "!pip install --upgrade -q jaxlib\n",
        "!pip install --upgrade -q trax==1.3.6\n",
        "!pip install --upgrade -q sentencepiece\n",
        "!pip install --upgrade -q gin \n",
        "\n",
        "# Make sure the Colab Runtime is set to Accelerator: TPU.\n",
        "import requests\n",
        "import os\n",
        "if 'TPU_DRIVER_MODE' not in globals():\n",
        "  url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver0.1-dev20191206'\n",
        "  resp = requests.post(url)\n",
        "  TPU_DRIVER_MODE = 1\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "from jax.config import config\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "print(config.FLAGS.jax_backend_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv0PuxC3F-jn"
      },
      "source": [
        "import gin\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "# Zipping and downloading files\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Trax\n",
        "import jax\n",
        "import trax\n",
        "from trax.data import inputs\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# NLP Vocab Generation\n",
        "import sentencepiece as spm\n",
        "\n",
        "# TensorFlow\n",
        "from tensorflow.compat.v1.io.gfile import GFile\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv4xf_1NIBpy"
      },
      "source": [
        "# Download `The Republic` by Plato text\n",
        "FILENAME = '.'.join(['the_republic', 'txt'])\n",
        "URL = 'http://www.gutenberg.org/cache/epub/1497/pg1497.txt'\n",
        "tf.keras.utils.get_file(FILENAME, URL, cache_dir='.')\n",
        "TEXT_PATH = os.path.join('datasets', FILENAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRnIoCBkNXyd"
      },
      "source": [
        "# Use only novel text\n",
        "with GFile('/content/Intelligent-Virtuoso-Music-TXT-Dataset1.csv') as f:\n",
        "    text = f.read()\n",
        "\n",
        "'''start = text.rfind('INTRODUCTION AND ANALYSIS')\n",
        "start = text.find('The Republic', start + 1)\n",
        "end = text.rfind('End of the Project Gutenberg EBook of The Republic, by Plato')\n",
        "text = text[start:end].strip()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l9Znw2bS-Pg"
      },
      "source": [
        "# Train a BPE model on the text\n",
        "spm.SentencePieceTrainer.train('--input=/content/Intelligent-Virtuoso-Music-TXT-Dataset1.txt \\\n",
        "                                --model_prefix=cp.320 \\\n",
        "                                --vocab_size=320 \\\n",
        "                                --model_type=bpe')\n",
        "# Load BPE vocabulary\n",
        "TOKENIZER = spm.SentencePieceProcessor() \n",
        "TOKENIZER.load('cp.320.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQwhEqJzS-I2"
      },
      "source": [
        "# Tokenize\n",
        "IDS = TOKENIZER.EncodeAsIds(text)\n",
        "IDS = np.asarray(IDS, dtype=np.int32)\n",
        "PAD_AMOUNT = 512 * 1024 - len(IDS)\n",
        "print(\"Number of tokens:\", IDS.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdKnx2FyS-AO"
      },
      "source": [
        "# Set up the data pipeline.\n",
        "def my_inputs(n_devices):\n",
        "  while True:\n",
        "    inputs = []\n",
        "    mask = []\n",
        "    pad_amounts = np.random.choice(PAD_AMOUNT, n_devices)\n",
        "    for i in range(n_devices):\n",
        "      inputs.append(np.pad(IDS, (pad_amounts[i], PAD_AMOUNT - pad_amounts[i]), # Pad IDS by different amount for each device\n",
        "                            mode='constant'))\n",
        "      mask.append(np.pad(np.ones_like(IDS, dtype=np.float32),\n",
        "                          (pad_amounts[i], PAD_AMOUNT - pad_amounts[i]),\n",
        "                          mode='constant'))\n",
        "    inputs = np.stack(inputs)\n",
        "    mask = np.stack(mask)\n",
        "    yield (inputs, inputs, mask)\n",
        "\n",
        "print(\"(device count, tokens per device) = \",\n",
        "      next(my_inputs(trax.fastmath.device_count()))[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NeFGlGGS959"
      },
      "source": [
        "# Configure hyperparameters.\n",
        "gin.parse_config(\"\"\"\n",
        "import trax.layers\n",
        "import trax.models\n",
        "import trax.optimizers\n",
        "import trax.data.inputs\n",
        "import trax.supervised.trainer_lib\n",
        "\n",
        "# Parameters that will vary between experiments:\n",
        "# ==============================================================================\n",
        "train.model = @trax.models.ReformerLM\n",
        "# Model will have 6 layers, alternating between the LSH attention\n",
        "# and local attention within a certain context window.\n",
        "n_layers = 6\n",
        "attn_type = [\n",
        "  @trax.layers.SelfAttention,\n",
        "  @LSHSelfAttention,  \n",
        "  @trax.layers.SelfAttention,\n",
        "  @LSHSelfAttention,\n",
        "  @trax.layers.SelfAttention,\n",
        "  @LSHSelfAttention,\n",
        "  ]\n",
        "share_qk = False  # LSH attention ignores this flag and always shares q & k\n",
        "n_heads = 2\n",
        "attn_kv = 64\n",
        "dropout = 0.05\n",
        "n_tokens = 524288\n",
        "\n",
        "# Parameters for multifactor:\n",
        "# ==============================================================================\n",
        "multifactor.constant = 0.01\n",
        "multifactor.factors = 'constant * linear_warmup * cosine_decay'\n",
        "multifactor.warmup_steps = 100\n",
        "multifactor.steps_per_cycle = 900\n",
        "\n",
        "# Parameters for Adam:\n",
        "# ==============================================================================\n",
        "Adam.weight_decay_rate=0.0\n",
        "Adam.b1 = 0.86\n",
        "Adam.b2 = 0.92\n",
        "Adam.eps = 1e-9\n",
        "\n",
        "# Parameters for SelfAttention:\n",
        "# ==============================================================================\n",
        "trax.layers.SelfAttention.attention_dropout = 0.05\n",
        "trax.layers.SelfAttention.chunk_len = 64\n",
        "trax.layers.SelfAttention.n_chunks_before = 1\n",
        "trax.layers.SelfAttention.n_parallel_heads = 1\n",
        "\n",
        "# Parameters for LSHSelfAttention:\n",
        "# ==============================================================================\n",
        "LSHSelfAttention.attention_dropout = 0.0\n",
        "LSHSelfAttention.chunk_len = 64\n",
        "LSHSelfAttention.n_buckets = [64, 128]\n",
        "LSHSelfAttention.n_chunks_after = 0\n",
        "LSHSelfAttention.n_chunks_before = 1\n",
        "LSHSelfAttention.n_hashes = 1\n",
        "LSHSelfAttention.n_parallel_heads = 1\n",
        "LSHSelfAttention.predict_drop_len = 128\n",
        "LSHSelfAttention.predict_mem_len = 1024\n",
        "\n",
        "# Parameters for ReformerLM:\n",
        "# ==============================================================================\n",
        "ReformerLM.attention_type = %attn_type\n",
        "ReformerLM.d_attention_key = %attn_kv\n",
        "ReformerLM.d_attention_value = %attn_kv\n",
        "ReformerLM.d_model = 256\n",
        "ReformerLM.d_ff = 512\n",
        "ReformerLM.dropout = %dropout\n",
        "ReformerLM.ff_activation = @trax.layers.Relu\n",
        "ReformerLM.max_len = %n_tokens\n",
        "ReformerLM.mode = 'train'\n",
        "ReformerLM.n_heads = %n_heads\n",
        "ReformerLM.n_layers = %n_layers\n",
        "ReformerLM.vocab_size = 320\n",
        "ReformerLM.axial_pos_shape = (512, 1024)\n",
        "ReformerLM.d_axial_pos_embs= (64, 192)\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8ay-6VxS9xw"
      },
      "source": [
        "# Trainer.\n",
        "output_dir = os.path.expanduser('model')\n",
        "!rm -f ~/model/model.pkl.gz  # Remove old model\n",
        "\n",
        "trainer = trax.supervised.Trainer(\n",
        "    model=trax.models.ReformerLM,\n",
        "    loss_fn=trax.layers.CrossEntropyLoss(),\n",
        "    optimizer=trax.optimizers.Adam,\n",
        "    lr_schedule=trax.lr.multifactor(),\n",
        "    inputs=trax.data.inputs.Inputs(my_inputs),\n",
        "    output_dir=output_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf0HITY7Wz8C"
      },
      "source": [
        "# Train Model\n",
        "import tqdm\n",
        "for _ in tqdm.tqdm(range(50)):\n",
        "  trainer.train_epoch(n_steps=100, n_eval_steps=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEikLctyte-m"
      },
      "source": [
        "# Zip directory contents\n",
        "shutil.make_archive(\"project\", \"zip\", \".\")\n",
        "\n",
        "# Download zipped directory\n",
        "files.download('project.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLebeiAFrItK"
      },
      "source": [
        "# In the Reformer paper, increasing the number of hashing rounds helps with quality. \n",
        "# The number of hashing rounds at can be increased at evaluation time only.\n",
        "gin.parse_config(\"\"\"LSHSelfAttention.n_hashes = 8\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thdiRvGDrJhy"
      },
      "source": [
        "# Load the trained Reformer in 'predict' mode\n",
        "model = trax.models.ReformerLM(mode='predict')\n",
        "output_dir = os.path.expanduser('model')\n",
        "model.init_from_file(os.path.join(output_dir,'model.pkl.gz'),\n",
        "                     weights_only=True)\n",
        "\n",
        "# Sample from ReformerLM\n",
        "output_token_ids = trax.supervised.decoding.autoregressive_sample(\n",
        "    model, temperature=0.2, max_length=1024, accelerate=True)\n",
        "\n",
        "# Decode token IDs\n",
        "# Reformer outputed a batch with one item so access it using [0]\n",
        "# tolist() converts from int64 to int, the type SentencePiece expects\n",
        "input = TOKENIZER.DecodeIds(output_token_ids[0].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "f7O-q9BG7KjQ"
      },
      "source": [
        "#@title Install all dependencies (run only once per session)\r\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\r\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\r\n",
        "!pip install midi2audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gBP4FQwq7LNb"
      },
      "source": [
        "#@title Import all needed modules\r\n",
        "\r\n",
        "print('Loading needed modules. Please wait...')\r\n",
        "import os\r\n",
        "if not os.path.exists('/content/Dataset'):\r\n",
        "    os.makedirs('/content/Dataset')\r\n",
        "\r\n",
        "os.chdir('/content/minGPT')\r\n",
        "# make deterministic\r\n",
        "set_seed(42)\r\n",
        "\r\n",
        "import tqdm.auto\r\n",
        "import pickle\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "import time\r\n",
        "import math\r\n",
        "import datetime\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "\r\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\r\n",
        "import TMIDI\r\n",
        "import MIDI\r\n",
        "\r\n",
        "import tqdm.auto\r\n",
        "\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "from midi2audio import FluidSynth\r\n",
        "from IPython.display import display, Javascript, HTML, Audio\r\n",
        "\r\n",
        "from google.colab import output, drive\r\n",
        "\r\n",
        "dtype = torch.float\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\r\n",
        "print('Available Processing Device is:', device)\r\n",
        "os.chdir('/content/')\r\n",
        "print('Loading complete. Enjoy! :)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "j2Lz-pZt7W6-"
      },
      "source": [
        "#@title Convert to MIDI from TXT (w/Tegridy MIDI-TXT Processor)\r\n",
        "\r\n",
        "#@markdown Standard MIDI timings are 400/120(80)\r\n",
        "\r\n",
        "#@markdown Silence offset is model specific and usually the same so most likely it will need to be set up only once. Otherwise, please play with the settings utill you will find the right ones for your particular model.\r\n",
        "\r\n",
        "#@markdown line_by_line_dataset option is for support of legacy datasets (IV 1.0-1.1). From now on IV will be using new line-by-line datasets for compatibility with AI BPE tokenizers.\r\n",
        "\r\n",
        "line_by_line_dataset = False #@param {type:\"boolean\"}\r\n",
        "dataset_MIDI_events_time_denominator = 100 #@param {type:\"slider\", min:1, max:100, step:1}\r\n",
        "number_of_ticks_per_quarter = 425 #@param {type:\"slider\", min:1, max:1000, step:8}\r\n",
        "start_from_this_generated_event = 0 #@param {type:\"slider\", min:0, max:100, step:1}\r\n",
        "remove_generated_silence_if_needed = False #@param {type:\"boolean\"}\r\n",
        "silence_offset_from_start = 75000 #@param {type:\"integer\"}\r\n",
        "simulate_velocity = False #@param {type:\"boolean\"}\r\n",
        "\r\n",
        "song_score = []\r\n",
        "n = 0\r\n",
        "z = 0\r\n",
        "detailed_stats = 0\r\n",
        "\r\n",
        "#with open('/content/TMIDI-TXT-Composition.txt', 'r') as file:\r\n",
        "#    input=file.read()\r\n",
        "\r\n",
        "output_signature = 'Intelligent VIRTUOSO'\r\n",
        "\r\n",
        "midi_data, n, z, detailed_stats = TMIDI.Tegridy_TXT_MIDI_Processor(input,\r\n",
        "                                             line_by_line_dataset,\r\n",
        "                                             dataset_MIDI_events_time_denominator,\r\n",
        "                                             number_of_ticks_per_quarter,\r\n",
        "                                             start_from_this_generated_event,\r\n",
        "                                             remove_generated_silence_if_needed,\r\n",
        "                                             silence_offset_from_start,\r\n",
        "                                             simulate_velocity,\r\n",
        "                                             output_signature)\r\n",
        "                                            \r\n",
        "\r\n",
        "# Stuff for datetime stamp\r\n",
        "now = ''\r\n",
        "now_n = str(datetime.now())\r\n",
        "now_n = now_n.replace(' ', '_')\r\n",
        "now_n = now_n.replace(':', '_')\r\n",
        "now = now_n.replace('.', '_')\r\n",
        "    \r\n",
        "fname = '/content/Intelligent-VIRTUOSO-Composition-' + 'generated-on-' + str(now) + '.mid'  \r\n",
        "\r\n",
        "\r\n",
        "with open(fname, 'wb') as midi_file:\r\n",
        "    midi_file.write(midi_data)\r\n",
        "    midi_file.close()\r\n",
        "print('Done!')\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "files.download(fname)\r\n",
        "print('Detailed MIDI stats:')\r\n",
        "detailed_stats"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}