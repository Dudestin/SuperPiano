{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Super_Piano_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/SuperPiano/blob/master/Super_Piano_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9opKSK2RSDRg",
        "colab_type": "text"
      },
      "source": [
        "# Super Piano 3: Google Music Transformer\n",
        "## Generating Music with Long-Term structure\n",
        "### Based on 2019 ICLR paper by Cheng-Zhi Anna Huang, Google Brain and Damon Gwinn code/repo https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "Huge thanks go out to the following people who contributed the code/repos used in this colab. Additional contributors are listed in the code as well.\n",
        "\n",
        "1) Kevin-Yang https://github.com/jason9693/midi-neural-processor\n",
        "\n",
        "2) gudgud96 for fixing Kevin's MIDI Encoder properly https://github.com/gudgud96\n",
        "\n",
        "2) jinyi12, Zac Koh, Akamight, Zhang https://github.com/COMP6248-Reproducability-Challenge/music-transformer-comp6248\n",
        "\n",
        "Thank you so much for your hard work and for sharing it with the world :)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05hD19W0hSCP",
        "colab_type": "text"
      },
      "source": [
        "###Setup Environment and Dependencies. Check GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ror_UJUp7wlO",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Check if GPU (driver) is avaiiable (you do not want to run this on CPU, trust me)\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paYvoZHihtux",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Clone/Install all dependencies\n",
        "!git clone https://github.com/asigalov61/midi-neural-processor\n",
        "!git clone https://github.com/asigalov61/MusicTransformer-Pytorch\n",
        "!pip install tqdm\n",
        "!pip install progress\n",
        "!pip install pretty-midi\n",
        "!pip install pypianoroll\n",
        "!pip install matplotlib\n",
        "!pip install librosa\n",
        "!pip install scipy\n",
        "!pip install pillow\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!pip install mir_eval\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 /content/font.sf2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM71tUPVfffi",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Import all needed modules\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "# For plotting\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib.use('SVG')\n",
        "#%matplotlib inline\n",
        "#matplotlib.get_backend()\n",
        "import mir_eval.display\n",
        "import librosa\n",
        "import librosa.display\n",
        "# For rendering output audio\n",
        "import pretty_midi\n",
        "from midi2audio import FluidSynth\n",
        "from google.colab import output\n",
        "from IPython.display import display, Javascript, HTML, Audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gd-O5LZyJGD",
        "colab_type": "text"
      },
      "source": [
        "#Option 1: MAESTRO DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bGqw8o6oxUY",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Download Google Magenta MAESTRO v.2.0.0 Piano MIDI Dataset (~1300 MIDIs)\n",
        "%cd /content/MusicTransformer-Pytorch/dataset/\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip maestro-v2.0.0-midi.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXiyUuuonMqM",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Prepare directory sctructure and MIDI processor\n",
        "!mv midi-neural-processor midi_processor\n",
        "%cd /content/MusicTransformer-Pytorch/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN-bpkEGxSMY",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Process MAESTRO MIDI DataSet\n",
        "!python3 preprocess_midi.py '/content/MusicTransformer-Pytorch/dataset/maestro-v2.0.0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwisXl2Iy_Xf",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Activate Tensorboard Graphs/Stats to monitor/evaluate model perfomance during and after training runs\n",
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "%tensorboard --logdir /content/MusicTransformer-Pytorch/rpr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbv_sJyLq5om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "outputId": "2d4e60f2-f917-4fb8-e114-feffbbcd8dcb"
      },
      "source": [
        "#@title Start to Train the Model\n",
        "batch_size = 4 #@param {type:\"slider\", min:0, max:8, step:1}\n",
        "number_of_training_epochs = 100 #@param {type:\"slider\", min:0, max:200, step:1}\n",
        "maximum_output_MIDI_sequence = 2048 #@param {type:\"slider\", min:0, max:8192, step:128}\n",
        "!python3 train.py -output_dir rpr --rpr -batch_size=$batch_size -epochs=$number_of_training_epochs -max_sequence=$maximum_output_MIDI_sequence #-n_layers -num_heads -d_model -dim_feedforward"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================\n",
            "Epoch 76  Batch 120 / 242\n",
            "LR: 0.0003269608440491377\n",
            "Train loss: 2.061943769454956\n",
            "\n",
            "Time (s): 0.6528997421264648\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 121 / 242\n",
            "LR: 0.00032695189639115674\n",
            "Train loss: 1.9099819660186768\n",
            "\n",
            "Time (s): 0.6561064720153809\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 122 / 242\n",
            "LR: 0.0003269429494677243\n",
            "Train loss: 1.9431378841400146\n",
            "\n",
            "Time (s): 0.6562628746032715\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 123 / 242\n",
            "LR: 0.00032693400327874\n",
            "Train loss: 1.8389219045639038\n",
            "\n",
            "Time (s): 0.6572952270507812\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 124 / 242\n",
            "LR: 0.0003269250578241032\n",
            "Train loss: 1.9440113306045532\n",
            "\n",
            "Time (s): 0.6585326194763184\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 125 / 242\n",
            "LR: 0.00032691611310371336\n",
            "Train loss: 1.9875966310501099\n",
            "\n",
            "Time (s): 0.6585068702697754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 126 / 242\n",
            "LR: 0.00032690716911747033\n",
            "Train loss: 1.9716134071350098\n",
            "\n",
            "Time (s): 0.6544439792633057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 127 / 242\n",
            "LR: 0.0003268982258652734\n",
            "Train loss: 2.0053038597106934\n",
            "\n",
            "Time (s): 0.6532437801361084\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 128 / 242\n",
            "LR: 0.00032688928334702235\n",
            "Train loss: 1.817086100578308\n",
            "\n",
            "Time (s): 0.6596238613128662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 129 / 242\n",
            "LR: 0.0003268803415626168\n",
            "Train loss: 1.9296479225158691\n",
            "\n",
            "Time (s): 0.6543753147125244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 130 / 242\n",
            "LR: 0.00032687140051195624\n",
            "Train loss: 1.7878155708312988\n",
            "\n",
            "Time (s): 0.653069257736206\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 131 / 242\n",
            "LR: 0.00032686246019494045\n",
            "Train loss: 1.9389134645462036\n",
            "\n",
            "Time (s): 0.6533994674682617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 132 / 242\n",
            "LR: 0.0003268535206114691\n",
            "Train loss: 1.771931529045105\n",
            "\n",
            "Time (s): 0.652273416519165\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 133 / 242\n",
            "LR: 0.0003268445817614417\n",
            "Train loss: 1.7972997426986694\n",
            "\n",
            "Time (s): 0.6516151428222656\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 134 / 242\n",
            "LR: 0.0003268356436447583\n",
            "Train loss: 2.0420961380004883\n",
            "\n",
            "Time (s): 0.6565275192260742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 135 / 242\n",
            "LR: 0.0003268267062613183\n",
            "Train loss: 1.7396854162216187\n",
            "\n",
            "Time (s): 0.6593174934387207\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 136 / 242\n",
            "LR: 0.00032681776961102175\n",
            "Train loss: 2.174238681793213\n",
            "\n",
            "Time (s): 0.655327320098877\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 137 / 242\n",
            "LR: 0.0003268088336937682\n",
            "Train loss: 2.0236639976501465\n",
            "\n",
            "Time (s): 0.6562192440032959\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 138 / 242\n",
            "LR: 0.0003267998985094576\n",
            "Train loss: 1.80813467502594\n",
            "\n",
            "Time (s): 0.6569395065307617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 139 / 242\n",
            "LR: 0.00032679096405798956\n",
            "Train loss: 1.8401334285736084\n",
            "\n",
            "Time (s): 0.6575520038604736\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 140 / 242\n",
            "LR: 0.00032678203033926405\n",
            "Train loss: 1.9347563982009888\n",
            "\n",
            "Time (s): 0.6561696529388428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 141 / 242\n",
            "LR: 0.0003267730973531809\n",
            "Train loss: 2.0180888175964355\n",
            "\n",
            "Time (s): 0.6510846614837646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 142 / 242\n",
            "LR: 0.00032676416509964\n",
            "Train loss: 1.7915253639221191\n",
            "\n",
            "Time (s): 0.652451753616333\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 143 / 242\n",
            "LR: 0.0003267552335785412\n",
            "Train loss: 1.7286622524261475\n",
            "\n",
            "Time (s): 0.6585214138031006\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 144 / 242\n",
            "LR: 0.00032674630278978445\n",
            "Train loss: 1.8317036628723145\n",
            "\n",
            "Time (s): 0.6566867828369141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 145 / 242\n",
            "LR: 0.0003267373727332695\n",
            "Train loss: 2.063870668411255\n",
            "\n",
            "Time (s): 0.6701927185058594\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 146 / 242\n",
            "LR: 0.00032672844340889655\n",
            "Train loss: 1.7951117753982544\n",
            "\n",
            "Time (s): 0.6610677242279053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 147 / 242\n",
            "LR: 0.0003267195148165654\n",
            "Train loss: 1.7474150657653809\n",
            "\n",
            "Time (s): 0.6635994911193848\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 148 / 242\n",
            "LR: 0.00032671058695617607\n",
            "Train loss: 2.0265796184539795\n",
            "\n",
            "Time (s): 0.652055025100708\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 149 / 242\n",
            "LR: 0.00032670165982762856\n",
            "Train loss: 1.7920911312103271\n",
            "\n",
            "Time (s): 0.664208173751831\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 150 / 242\n",
            "LR: 0.0003266927334308229\n",
            "Train loss: 1.8862929344177246\n",
            "\n",
            "Time (s): 0.6491589546203613\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 151 / 242\n",
            "LR: 0.0003266838077656592\n",
            "Train loss: 1.732440710067749\n",
            "\n",
            "Time (s): 0.6517796516418457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 152 / 242\n",
            "LR: 0.0003266748828320373\n",
            "Train loss: 2.008183240890503\n",
            "\n",
            "Time (s): 0.6521434783935547\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 153 / 242\n",
            "LR: 0.0003266659586298575\n",
            "Train loss: 1.6811290979385376\n",
            "\n",
            "Time (s): 0.6557042598724365\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 154 / 242\n",
            "LR: 0.0003266570351590198\n",
            "Train loss: 1.9659072160720825\n",
            "\n",
            "Time (s): 0.6598961353302002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 155 / 242\n",
            "LR: 0.0003266481124194243\n",
            "Train loss: 2.0011067390441895\n",
            "\n",
            "Time (s): 0.6563000679016113\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 156 / 242\n",
            "LR: 0.00032663919041097127\n",
            "Train loss: 2.197525978088379\n",
            "\n",
            "Time (s): 0.6509451866149902\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 157 / 242\n",
            "LR: 0.00032663026913356066\n",
            "Train loss: 2.0224292278289795\n",
            "\n",
            "Time (s): 0.6556024551391602\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 158 / 242\n",
            "LR: 0.00032662134858709276\n",
            "Train loss: 1.8866790533065796\n",
            "\n",
            "Time (s): 0.6547975540161133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 76  Batch 159 / 242\n",
            "LR: 0.00032661242877146787\n",
            "Train loss: 1.9117789268493652\n",
            "\n",
            "Time (s): 0.6533136367797852\n",
            "=========================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1D-o-E-TnI8",
        "colab_type": "text"
      },
      "source": [
        "###Evaluate the resulted models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQLOmv7wrOos",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Evaluate Best Resulting Accuracy Model (best_acc_weights.pickle)\n",
        "!python3 evaluate.py -model_weights rpr/results/best_acc_weights.pickle --rpr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7QftGOfTyx2",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Evaluate Best Resulting Loss Model (best_loss_weights.pickle)\n",
        "!python3 evaluate.py -model_weights rpr/results/best_loss_weights.pickle --rpr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MusrrrOxt1uy",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Graph the results\n",
        "import argparse\n",
        "import os\n",
        "import csv\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RESULTS_FILE = \"results.csv\"\n",
        "EPOCH_IDX = 0\n",
        "LR_IDX = 1\n",
        "EVAL_LOSS_IDX = 4\n",
        "EVAL_ACC_IDX = 5\n",
        "\n",
        "SPLITTER = '?'\n",
        "\n",
        "\n",
        "def graph_results(input_dirs=\"/content/MusicTransformer-Pytorch/rpr/results\", output_dir=None, model_names=None, epoch_start=0, epoch_end=None):\n",
        "    \"\"\"\n",
        "    ----------\n",
        "    Author: Damon Gwinn\n",
        "    ----------\n",
        "    Graphs model training and evaluation data\n",
        "    ----------\n",
        "    \"\"\"\n",
        "\n",
        "    input_dirs = input_dirs.split(SPLITTER)\n",
        "\n",
        "    if(model_names is not None):\n",
        "        model_names = model_names.split(SPLITTER)\n",
        "        if(len(model_names) != len(input_dirs)):\n",
        "            print(\"Error: len(model_names) != len(input_dirs)\")\n",
        "            return\n",
        "\n",
        "    #Initialize Loss and Accuracy arrays\n",
        "    loss_arrs = []\n",
        "    accuracy_arrs = []\n",
        "    epoch_counts = []\n",
        "    lrs = []\n",
        "\n",
        "    for input_dir in input_dirs:\n",
        "        loss_arr = []\n",
        "        accuracy_arr = []\n",
        "        epoch_count = []\n",
        "        lr_arr = []\n",
        "\n",
        "        f = os.path.join(input_dir, RESULTS_FILE)\n",
        "        with open(f, \"r\") as i_stream:\n",
        "            reader = csv.reader(i_stream)\n",
        "            next(reader)\n",
        "\n",
        "            lines = [line for line in reader]\n",
        "\n",
        "        if(epoch_end is None):\n",
        "            epoch_end = math.inf\n",
        "\n",
        "        epoch_start = max(epoch_start, 0)\n",
        "        epoch_start = min(epoch_start, epoch_end)\n",
        "\n",
        "        for line in lines:\n",
        "            epoch = line[EPOCH_IDX]\n",
        "            lr = line[LR_IDX]\n",
        "            accuracy = line[EVAL_ACC_IDX]\n",
        "            loss = line[EVAL_LOSS_IDX]\n",
        "\n",
        "            if(int(epoch) >= epoch_start and int(epoch) < epoch_end):\n",
        "                accuracy_arr.append(float(accuracy))\n",
        "                loss_arr.append(float(loss))\n",
        "                epoch_count.append(int(epoch))\n",
        "                lr_arr.append(float(lr))\n",
        "\n",
        "        loss_arrs.append(loss_arr)\n",
        "        accuracy_arrs.append(accuracy_arr)\n",
        "        epoch_counts.append(epoch_count)\n",
        "        lrs.append(lr_arr)\n",
        "\n",
        "    if(output_dir is not None):\n",
        "        try:\n",
        "            os.mkdir(output_dir)\n",
        "        except OSError:\n",
        "            print (\"Creation of the directory %s failed\" % output_dir)\n",
        "        else:\n",
        "            print (\"Successfully created the directory %s\" % output_dir)\n",
        "\n",
        "    ##### LOSS #####\n",
        "    for i in range(len(loss_arrs)):\n",
        "        if(model_names is None):\n",
        "            name = None\n",
        "        else:\n",
        "            name = model_names[i]\n",
        "\n",
        "        #Create and save plots to output folder\n",
        "        plt.plot(epoch_counts[i], loss_arrs[i], label=name)\n",
        "        plt.title(\"Loss Results\")\n",
        "        plt.ylabel('Loss (Cross Entropy)')\n",
        "        plt.xlabel('Epochs')\n",
        "        fig1 = plt.gcf()\n",
        "\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    if(output_dir is not None):\n",
        "        fig1.savefig(os.path.join(output_dir, 'loss_graph.png'))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    ##### ACCURACY #####\n",
        "    for i in range(len(accuracy_arrs)):\n",
        "        if(model_names is None):\n",
        "            name = None\n",
        "        else:\n",
        "            name = model_names[i]\n",
        "\n",
        "        #Create and save plots to output folder\n",
        "        plt.plot(epoch_counts[i], accuracy_arrs[i], label=name)\n",
        "        plt.title(\"Accuracy Results\")\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epochs')\n",
        "        fig2 = plt.gcf()\n",
        "\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    if(output_dir is not None):\n",
        "        fig2.savefig(os.path.join(output_dir, 'accuracy_graph.png'))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    ##### LR #####\n",
        "    for i in range(len(lrs)):\n",
        "        if(model_names is None):\n",
        "            name = None\n",
        "        else:\n",
        "            name = model_names[i]\n",
        "\n",
        "        #Create and save plots to output folder\n",
        "        plt.plot(epoch_counts[i], lrs[i], label=name)\n",
        "        plt.title(\"Learn Rate Results\")\n",
        "        plt.ylabel('Learn Rate')\n",
        "        plt.xlabel('Epochs')\n",
        "        fig2 = plt.gcf()\n",
        "\n",
        "    plt.legend(loc=\"upper left\")\n",
        "\n",
        "    if(output_dir is not None):\n",
        "        fig2.savefig(os.path.join(output_dir, 'lr_graph.png'))\n",
        "\n",
        "    plt.show()\n",
        "graph_results('/content/MusicTransformer-Pytorch/rpr/results', model_names='rpr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxHrTsFUdn-r",
        "colab_type": "text"
      },
      "source": [
        "To have the model continue your custom MIDI enter the following into the custom_MIDI field below:\n",
        "\n",
        "-primer_file '/content/MusicTransformer-Pytorch/dataset/maestro-v2.0.0/2018/MIDI-Unprocessed_Chamber1_MID--AUDIO_07_R3_2018_wav--2.midi'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czNulONr4tB6",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Generate, Plot, Graph, Save, Download, and Render the resulting output\n",
        "number_of_tokens_to_generate = 2048 #@param {type:\"slider\", min:128, max:8192, step:64}\n",
        "priming_sequence_length = 512 #@param {type:\"slider\", min:0, max:2048, step:8}\n",
        "maximum_possible_output_sequence = 2048 #@param {type:\"slider\", min:0, max:4096, step:128}\n",
        "select_model = \"/content/MusicTransformer-Pytorch/rpr/results/best_acc_weights.pickle\" #@param [\"/content/MusicTransformer-Pytorch/rpr/results/best_acc_weights.pickle\", \"/content/MusicTransformer-Pytorch/rpr/results/best_loss_weights.pickle\"]\n",
        "custom_MIDI = \"-primer_file '/content/MusicTransformer-Pytorch/unconditional-fast.mid'\" #@param {type:\"string\"}\n",
        "\n",
        "import processor\n",
        "from processor import encode_midi, decode_midi\n",
        "\n",
        "!python generate.py -output_dir output -model_weights=$select_model --rpr -target_seq_length=$number_of_tokens_to_generate -num_prime=$priming_sequence_length -max_sequence=$maximum_possible_output_sequence $custom_MIDI #\n",
        "\n",
        "print('Successfully exported the output to output folder. To primer.mid and rand.mid')\n",
        "\n",
        "# set the src and play\n",
        "FluidSynth(\"/content/font.sf2\").midi_to_audio('/content/MusicTransformer-Pytorch/output/rand.mid', '/content/MusicTransformer-Pytorch/output/output.wav')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/MusicTransformer-Pytorch/output/rand.mid')\n",
        "files.download('/content/MusicTransformer-Pytorch/output/primer.mid')\n",
        "\n",
        "Audio('/content/MusicTransformer-Pytorch/output/output.wav')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG48uyKGzcTI",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Plot and Graph the Output :)\n",
        "graphs_length_inches = 18 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 6 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "rendered_wav_graph_height = 3 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib.use('SVG')\n",
        "# For plotting\n",
        "import mir_eval.display\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "midi_data = pretty_midi.PrettyMIDI('/content/MusicTransformer-Pytorch/output/rand.mid')\n",
        "\n",
        "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "\n",
        "\n",
        "roll = np.zeros([int(graphs_length_inches), 128])\n",
        "# Plot the output\n",
        "\n",
        "track = Multitrack('/content/MusicTransformer-Pytorch/output/rand.mid', name='track')\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "ax2 = plot_piano_roll(midi_data, 24, 84)\n",
        "plt.show(block=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA9rWH5GYij3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}